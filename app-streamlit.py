import streamlit as st
import pandas as pd
import plotly.express as px
from google.oauth2 import service_account
import os
import gspread
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration de l'authentification Google Sheets
@st.cache_resource
def get_google_credentials():
    st.write("ğŸ”‘ Tentative de rÃ©cupÃ©ration des credentials Google...")
    try:
        credentials = service_account.Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=['https://www.googleapis.com/auth/spreadsheets.readonly']
        )
        st.write("âœ… Credentials Google rÃ©cupÃ©rÃ©es avec succÃ¨s")
        return credentials
    except Exception as e:
        st.error(f"âŒ Erreur lors de la rÃ©cupÃ©ration des credentials: {str(e)}")
        return None

def get_available_data_sources():
    st.write("ğŸ“‚ Recherche des sources de donnÃ©es disponibles...")
    
    sources = ["Google Sheets (Live)"]
    st.write(f"Sources initiales: {sources}")
    
    data_dir = 'data'
    try:
        if not os.path.exists(data_dir):
            st.warning(f"âš ï¸ Le dossier {data_dir} n'existe pas. CrÃ©ation du dossier...")
            os.makedirs(data_dir)
            st.success(f"âœ… Dossier {data_dir} crÃ©Ã© avec succÃ¨s")
        
        csv_files = [f for f in os.listdir(data_dir) if f.lower().endswith('.csv')]
        
        if csv_files:
            st.write(f"âœ… {len(csv_files)} fichier(s) CSV trouvÃ©(s)")
            for file in csv_files:
                st.write(f"ğŸ“„ Fichier trouvÃ©: {file}")
                sources.append(f"Fichier Local: {file}")
        else:
            st.write("â„¹ï¸ Aucun fichier CSV trouvÃ© dans le dossier data")
            
    except Exception as e:
        st.error(f"âŒ Erreur lors de la lecture du dossier data: {str(e)}")
    
    st.write(f"ğŸ“‹ Sources finales disponibles: {sources}")
    return sources

def load_sheets_data():
    st.write("ğŸ”„ DÃ©but du chargement des donnÃ©es Google Sheets")
    try:
        gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
        sheet = gc.open_by_key("1i8TU3c72YH-5sfAKcxmeuthgSeHcW3-ycg7cwzOtkrE")
        
        st.write("ğŸ“‘ Recherche de l'onglet 'RÃ©ponses'...")
        try:
            worksheet = sheet.worksheet("RÃ©ponses")
            st.write("âœ… Onglet 'RÃ©ponses' trouvÃ©")
        except Exception as e:
            st.error(f"âŒ Erreur lors de l'accÃ¨s Ã  l'onglet 'RÃ©ponses': {str(e)}")
            all_worksheets = sheet.worksheets()
            st.write("ğŸ“‘ Onglets disponibles:")
            for ws in all_worksheets:
                st.write(f"- {ws.title}")
            return None
        
        rows = worksheet.row_count
        cols = worksheet.col_count
        st.write(f"ğŸ“Š Dimensions de la feuille : {rows} lignes x {cols} colonnes")
        
        values = worksheet.get_all_values()
        if not values:
            st.error("âŒ Aucune donnÃ©e rÃ©cupÃ©rÃ©e")
            return None
            
        st.write(f"ğŸ“Š Nombre total de lignes rÃ©cupÃ©rÃ©es : {len(values)}")
        
        headers = values[0]
        df = pd.DataFrame(values[1:], columns=headers)
        df = df.dropna(axis=1, how='all')
        
        if 'Horodateur' in df.columns:
            df['Horodateur'] = pd.to_datetime(df['Horodateur'], format='%d/%m/%Y %H:%M:%S')
            st.write("âœ… Conversion des dates rÃ©ussie")
        
        st.write(f"ğŸ“Š Dimensions finales : {df.shape[0]} lignes x {df.shape[1]} colonnes")
        return df
        
    except Exception as e:
        st.error(f"âŒ Erreur lors du chargement : {type(e).__name__} - {str(e)}")
        return None

def load_local_data(filename):
    st.write(f"ğŸ“‚ Chargement du fichier local: {filename}")
    try:
        file_path = os.path.join('data', filename)
        st.write(f"ğŸ” Chemin complet: {file_path}")
        
        if not os.path.exists(file_path):
            st.error(f"âŒ Fichier non trouvÃ©: {file_path}")
            return None
            
        encodings = ['utf-8', 'latin-1', 'ISO-8859-1', 'cp1252']
        df = None
        successful_encoding = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                successful_encoding = encoding
                break
            except UnicodeDecodeError:
                continue
            
        if df is None:
            st.error("âŒ Impossible de lire le fichier avec les encodages standards")
            return None
            
        st.write(f"âœ… Fichier chargÃ© avec succÃ¨s (encodage: {successful_encoding})")
        st.write(f"ğŸ“Š Dimensions: {df.shape[0]} lignes x {df.shape[1]} colonnes")
        
        if 'Horodateur' in df.columns:
            try:
                df['Horodateur'] = pd.to_datetime(df['Horodateur'], format='%d/%m/%Y %H:%M:%S')
                st.write("âœ… Conversion des dates rÃ©ussie")
            except Exception as e:
                st.warning(f"âš ï¸ Erreur de conversion des dates: {str(e)}")
                
        st.write("ğŸ” VÃ©rification des donnÃ©es...")
        null_counts = df.isnull().sum()
        if null_counts.any():
            st.warning("âš ï¸ Valeurs manquantes dÃ©tectÃ©es:")
            for col, count in null_counts[null_counts > 0].items():
                st.write(f"- {col}: {count} valeurs manquantes")
                
        return df
        
    except Exception as e:
        st.error(f"âŒ Erreur lors du chargement: {type(e).__name__} - {str(e)}")
        return None

def handle_data_source_selection(data_source):
    if data_source == "Google Sheets (Live)":
        st.write("ğŸ”„ Chargement des donnÃ©es depuis Google Sheets...")
        return load_sheets_data()
    elif data_source.startswith("Fichier Local:"):
        filename = data_source.replace("Fichier Local: ", "")
        st.write(f"ğŸ“‚ Chargement du fichier local: {filename}")
        return load_local_data(filename)
    else:
        st.error("âŒ Source de donnÃ©es non reconnue")
        return None

def calculate_nps_metrics(df):
    """Calcule les mÃ©triques NPS avec gestion d'erreur amÃ©liorÃ©e"""
    # DÃ©finition de la colonne NPS
    nps_col = [col for col in df.columns if "recommand" in col.lower() and "Ã©chelle" in col.lower()]
    if not nps_col:
        st.error("âŒ Colonne NPS non trouvÃ©e")
        return None
    nps_col = nps_col[0]
    
    try:
        # Conversion en numÃ©rique avec nettoyage
        df['NPS_Score'] = pd.to_numeric(df[nps_col].str.extract('(\d+)')[0], errors='coerce')
        
        # Calcul des catÃ©gories NPS
        df['NPS_Category'] = df['NPS_Score'].apply(lambda x: 
            'Promoteur' if x >= 9 
            else 'Passif' if x >= 7 
            else 'DÃ©tracteur' if x >= 0 
            else None
        )
        
        # Calculs des pourcentages
        total_responses = len(df[df['NPS_Score'].notna()])
        if total_responses == 0:
            st.error("âŒ Aucune rÃ©ponse valide trouvÃ©e")
            return None
            
        promoters_pct = len(df[df['NPS_Category'] == 'Promoteur']) / total_responses * 100
        detractors_pct = len(df[df['NPS_Category'] == 'DÃ©tracteur']) / total_responses * 100
        passifs_pct = len(df[df['NPS_Category'] == 'Passif']) / total_responses * 100
        
        # Calcul du NPS
        nps_score = promoters_pct - detractors_pct
        
        return {
            'nps_score': round(nps_score, 1),
            'promoters_pct': round(promoters_pct, 1),
            'passifs_pct': round(passifs_pct, 1),
            'detractors_pct': round(detractors_pct, 1),
            'total_responses': total_responses
        }
    except Exception as e:
        st.error(f"âŒ Erreur dans le calcul du NPS: {str(e)}")
        return None

        return None
def show_data_source_tab(available_sources):
    """Nouvel onglet pour la gestion des sources de donnÃ©es"""
    st.header("ğŸ”„ Sources de DonnÃ©es")
    
    # SÃ©lection de la source
    data_source = st.selectbox(
        "Source des donnÃ©es",
        available_sources,
        help="SÃ©lectionnez la source des donnÃ©es Ã  analyser"
    )
    
    # Chargement des donnÃ©es
    df = handle_data_source_selection(data_source)
    
    if df is not None:
        # Affichage des informations sur les donnÃ©es
        st.subheader("ğŸ“Š Informations sur les donnÃ©es")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Nombre de rÃ©ponses", df.shape[0])
        with col2:
            st.metric("Nombre de colonnes", df.shape[1])
        with col3:
            date_range = df['Horodateur'].agg(['min', 'max'])
            st.metric("PÃ©riode couverte", f"{date_range['min'].strftime('%d/%m/%y')} - {date_range['max'].strftime('%d/%m/%y')}")
        
        # Affichage des valeurs manquantes
        st.subheader("ğŸ” Analyse de la qualitÃ© des donnÃ©es")
        null_counts = df.isnull().sum()
        if null_counts.any():
            st.warning("âš ï¸ Valeurs manquantes dÃ©tectÃ©es:")
            for col, count in null_counts[null_counts > 0].items():
                st.write(f"- {col}: {count} valeurs manquantes")
                
        return df
    return None

def show_nps_trends_tab(df):
    """Affichage amÃ©liorÃ© des tendances NPS"""
    st.header("ğŸ“ˆ Tableau de Bord NPS")
    
    metrics = calculate_nps_metrics(df)
    
    if metrics:
        # MÃ©triques principales avec style amÃ©liorÃ©
        st.subheader("MÃ©triques ClÃ©s")
        cols = st.columns(4)
        with cols[0]:
            st.metric("Score NPS", f"{metrics['nps_score']}%", 
                     help="Net Promoter Score = % Promoteurs - % DÃ©tracteurs")
        with cols[1]:
            st.metric("Promoteurs", f"{metrics['promoters_pct']}%",
                     help="Clients ayant donnÃ© une note de 9 ou 10")
        with cols[2]:
            st.metric("Passifs", f"{metrics['passifs_pct']}%",
                     help="Clients ayant donnÃ© une note de 7 ou 8")
        with cols[3]:
            st.metric("DÃ©tracteurs", f"{metrics['detractors_pct']}%",
                     help="Clients ayant donnÃ© une note de 0 Ã  6")
        
        # Ã‰volution temporelle
        st.subheader("Ã‰volution dans le temps")
        
        # PrÃ©paration des donnÃ©es mensuelles
        df['Month'] = df['Horodateur'].dt.to_period('M')
        monthly_stats = df.groupby('Month').apply(calculate_nps_metrics).apply(pd.Series)
        
        # Graphique d'Ã©volution NPS
        fig_nps = px.line(
            monthly_stats,
            x=monthly_stats.index.astype(str),
            y='nps_score',
            title="Ã‰volution du Score NPS",
            labels={'x': 'Mois', 'y': 'Score NPS (%)'},
            markers=True
        )
        fig_nps.update_layout(
            xaxis_title="Mois",
            yaxis_title="Score NPS (%)",
            hovermode='x unified'
        )
        st.plotly_chart(fig_nps)
        
        # Graphique de rÃ©partition
        categories_by_month = df.groupby(['Month', 'NPS_Category']).size().unstack(fill_value=0)
        categories_by_month_pct = categories_by_month.div(categories_by_month.sum(axis=1), axis=0) * 100
        
        fig_categories = px.bar(
            categories_by_month_pct,
            barmode='relative',
            title="RÃ©partition mensuelle Promoteurs/Passifs/DÃ©tracteurs",
            labels={'value': 'Pourcentage', 'Month': 'Mois'},
            color_discrete_map={
                'Promoteur': '#00CC96',
                'Passif': '#FFA15A',
                'DÃ©tracteur': '#EF553B'
            }
        )
        fig_categories.update_layout(
            xaxis_title="Mois",
            yaxis_title="RÃ©partition (%)",
            hovermode='x unified'
        )
        st.plotly_chart(fig_categories)



def show_recent_responses_tab(df):
    st.header("ğŸ” DerniÃ¨res RÃ©ponses")
    
    col1, col2 = st.columns(2)
    with col1:
        days_filter = st.slider("Nombre de jours Ã  afficher", 1, 90, 30)
    with col2:
        category_filter = st.multiselect(
            "CatÃ©gories Ã  afficher",
            ['Tous', 'Promoteur', 'Passif', 'DÃ©tracteur'],
            default=['Tous']
        )
    
    cutoff_date = pd.Timestamp.now() - pd.Timedelta(days=days_filter)
    recent_df = df[df['Horodateur'] > cutoff_date].copy()
    
    if 'Tous' not in category_filter:
        recent_df = recent_df[recent_df['NPS_Category'].isin(category_filter)]
    
    for _, row in recent_df.sort_values('Horodateur', ascending=False).iterrows():
        with st.expander(f"{row['Horodateur'].strftime('%d/%m/%Y')} - Score: {row['Sur une Ã©chelle de 1 Ã  10 , oÃ¹ 1 reprÃ©sente \"je ne recommanderais pas du tout\" et 10 \"Avec enthousiasme\", Ã  quel point Ãªtes-vous susceptible de conseiller Annette K Ã  un proche ?']} ({row['NPS_Category']})"):
            col1, col2 = st.columns(2)
            with col1:
                st.write("ğŸ’­ Commentaire NPS:")
                st.write(row["Pourquoi cette note ?"])
            with col2:
                st.write("ğŸ”„ ProbabilitÃ© de rÃ©abonnement:")
                st.write(f"Score: {row['Sur une Ã©chelle de 1 Ã  10, Quelle est la probabilitÃ© que vous soyez toujours abonnÃ© chez Annette K. dans 6 mois ?']}")
                st.write(row["Pourquoi cette rÃ©ponse ?"])

def main():
    st.title("Dashboard NPS Annette K.")
    
    available_sources = get_available_data_sources()
    
    # CrÃ©ation des onglets avec nouvel ordre
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“Š Tableau de Bord",
        "ğŸ“ RÃ©ponses RÃ©centes",
        "ğŸ”„ Sources de DonnÃ©es"
    ])
    
    # Gestion des donnÃ©es dans l'onglet Sources
    with tab3:
        df = show_data_source_tab(available_sources)
    
    # Affichage des autres onglets uniquement si les donnÃ©es sont chargÃ©es
    if df is not None:
        with tab1:
            show_nps_trends_tab(df)
        with tab2:
            show_recent_responses_tab(df)

if __name__ == "__main__":
    main()